#!/usr/bin/env python3
"""
Pronunciation Assessment Tool

ÄÃ¡nh giÃ¡ chi tiáº¿t phÃ¡t Ã¢m tá»« vÃ  cÃ¢u cá»§a ngÆ°á»i dÃ¹ng báº±ng cÃ¡ch so sÃ¡nh
cÃ¢u gá»‘c vá»›i káº¿t quáº£ Speech-to-Text.

Usage:
    python pronunciation-assessment.py
    
    Or import as module:
    from pronunciation_assessment import assess_pronunciation
"""

import re
import difflib
import yaml
import os
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass
import eng_to_ipa as ipa

@dataclass
class WordError:
    """LÆ°u thÃ´ng tin lá»—i cá»§a má»™t tá»«"""
    word: str
    expected_ipa: str
    actual_ipa: str
    error_type: str
    ipa_differences: List[str]

class PronunciationAssessment:
    """Class chÃ­nh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ phÃ¡t Ã¢m"""
    
    def __init__(self, data_file="user-data.yaml"):
        self.word_errors = []
        self.data_file = data_file
        self.user_data = self._load_user_data()
    
    def _clean_text(self, text: str) -> str:
        """LÃ m sáº¡ch text, loáº¡i bá» dáº¥u cÃ¢u vÃ  chuáº©n hÃ³a"""
        # Loáº¡i bá» dáº¥u cÃ¢u vÃ  kÃ½ tá»± Ä‘áº·c biá»‡t
        cleaned = re.sub(r'[^\w\s]', '', text.lower())
        # Chuáº©n hÃ³a khoáº£ng tráº¯ng
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        return cleaned
    
    def _get_ipa_pronunciation(self, word: str) -> str:
        """Chuyá»ƒn tá»« sang IPA"""
        try:
            return ipa.convert(word)
        except Exception:
            return word  # Fallback náº¿u khÃ´ng convert Ä‘Æ°á»£c
    
    def _calculate_word_similarity(self, word1: str, word2: str) -> float:
        """TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a 2 tá»«"""
        return difflib.SequenceMatcher(None, word1.lower(), word2.lower()).ratio()
    
    def _calculate_ipa_similarity(self, ipa1: str, ipa2: str) -> float:
        """TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng IPA giá»¯a 2 tá»«"""
        return difflib.SequenceMatcher(None, ipa1, ipa2).ratio()
    
    def _find_ipa_differences(self, expected_ipa: str, actual_ipa: str) -> List[str]:
        """TÃ¬m cÃ¡c Ã¢m IPA khÃ¡c nhau"""
        differences = []
        matcher = difflib.SequenceMatcher(None, expected_ipa, actual_ipa)
        
        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'replace':
                differences.append(f"'{expected_ipa[i1:i2]}' â†’ '{actual_ipa[j1:j2]}'")
            elif tag == 'delete':
                differences.append(f"missing '{expected_ipa[i1:i2]}'")
            elif tag == 'insert':
                differences.append(f"extra '{actual_ipa[j1:j2]}'")
        
        return differences
    
    def _advanced_word_matching(self, original_words: List[str], spoken_words: List[str]) -> List[Tuple[int, int, float]]:
        """
        Thuáº­t toÃ¡n matching nÃ¢ng cao Ä‘á»ƒ xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p:
        - 1 tá»« thÃ nh 2 tá»«
        - 2 tá»« thÃ nh 1 tá»«  
        - Tá»« bá»‹ thiáº¿u
        - Tá»« thá»«a
        """
        matches = []
        
        # Táº¡o ma tráº­n similarity
        similarity_matrix = []
        for i, orig_word in enumerate(original_words):
            row = []
            for j, spoken_word in enumerate(spoken_words):
                # So sÃ¡nh cáº£ text vÃ  IPA
                text_sim = self._calculate_word_similarity(orig_word, spoken_word)
                ipa_sim = self._calculate_ipa_similarity(
                    self._get_ipa_pronunciation(orig_word),
                    self._get_ipa_pronunciation(spoken_word)
                )
                combined_sim = (text_sim + ipa_sim) / 2
                row.append(combined_sim)
            similarity_matrix.append(row)
        
        # TÃ¬m best matches sá»­ dá»¥ng dynamic programming approach
        used_spoken = set()
        used_original = set()
        
        # TÃ¬m matches vá»›i threshold cao trÆ°á»›c
        high_threshold = 0.7
        for i in range(len(original_words)):
            if i in used_original:
                continue
            best_j = -1
            best_score = 0
            
            for j in range(len(spoken_words)):
                if j in used_spoken:
                    continue
                if similarity_matrix[i][j] > best_score and similarity_matrix[i][j] >= high_threshold:
                    best_score = similarity_matrix[i][j]
                    best_j = j
            
            if best_j != -1:
                matches.append((i, best_j, best_score))
                used_original.add(i)
                used_spoken.add(best_j)
        
        # Xá»­ lÃ½ cases phá»©c táº¡p: 1 tá»« gá»‘c match vá»›i nhiá»u tá»« spoken
        for i in range(len(original_words)):
            if i in used_original:
                continue
            
            # Thá»­ combine 2-3 tá»« spoken liÃªn tiáº¿p
            for window_size in [2, 3]:
                for j in range(len(spoken_words) - window_size + 1):
                    if any(k in used_spoken for k in range(j, j + window_size)):
                        continue
                    
                    combined_spoken = ''.join(spoken_words[j:j+window_size])
                    combined_sim = self._calculate_word_similarity(original_words[i], combined_spoken)
                    
                    if combined_sim >= 0.6:
                        matches.append((i, j, combined_sim))
                        used_original.add(i)
                        for k in range(j, j + window_size):
                            used_spoken.add(k)
                        break
                else:
                    continue
                break
        
        # Xá»­ lÃ½ remaining vá»›i threshold tháº¥p hÆ¡n
        low_threshold = 0.4
        for i in range(len(original_words)):
            if i in used_original:
                continue
            best_j = -1
            best_score = 0
            
            for j in range(len(spoken_words)):
                if j in used_spoken:
                    continue
                if similarity_matrix[i][j] > best_score and similarity_matrix[i][j] >= low_threshold:
                    best_score = similarity_matrix[i][j]
                    best_j = j
            
            if best_j != -1:
                matches.append((i, best_j, best_score))
                used_original.add(i)
                used_spoken.add(best_j)
        
        return sorted(matches, key=lambda x: x[0])
    
    def _load_user_data(self) -> List[Dict]:
        """Táº£i dá»¯ liá»‡u user tá»« file YAML"""
        if not os.path.exists(self.data_file):
            return []
        
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f) or []
                return data
        except Exception as e:
            print(f"Warning: Could not load {self.data_file}: {e}")
            return []
    
    def _save_user_data(self):
        """LÆ°u dá»¯ liá»‡u user vÃ o file YAML"""
        try:
            with open(self.data_file, 'w', encoding='utf-8') as f:
                yaml.dump(self.user_data, f, default_flow_style=False, 
                         allow_unicode=True, indent=2)
        except Exception as e:
            print(f"Error saving to {self.data_file}: {e}")
    
    def _extract_wrong_ipa_sounds(self, error: WordError) -> List[str]:
        """TrÃ­ch xuáº¥t cÃ¡c Ã¢m IPA bá»‹ sai tá»« WordError"""
        wrong_sounds = []
        
        for diff in error.ipa_differences:
            if 'â†’' in diff:
                # TrÆ°á»ng há»£p thay tháº¿: 'expected' â†’ 'actual'
                parts = diff.split(' â†’ ')
                if len(parts) == 2:
                    expected = parts[0].strip("'")
                    wrong_sounds.extend(list(expected))
            elif 'missing' in diff:
                # TrÆ°á»ng há»£p thiáº¿u Ã¢m: missing 'sound'
                missing_sound = diff.split("'")[1] if "'" in diff else ""
                if missing_sound:
                    wrong_sounds.extend(list(missing_sound))
            elif 'extra' in diff:
                # TrÆ°á»ng há»£p thá»«a Ã¢m: extra 'sound'
                extra_sound = diff.split("'")[1] if "'" in diff else ""
                if extra_sound:
                    wrong_sounds.extend(list(extra_sound))
        
        # Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t vÃ  khoáº£ng tráº¯ng
        wrong_sounds = [sound for sound in wrong_sounds if sound.strip() and sound not in [' ', '\t', '\n']]
        
        # Loáº¡i bá» duplicate nhÆ°ng giá»¯ thá»© tá»±
        seen = set()
        unique_sounds = []
        for sound in wrong_sounds:
            if sound not in seen:
                seen.add(sound)
                unique_sounds.append(sound)
        
        return unique_sounds
    
    def _save_assessment_result(self, original_text: str, spoken_text: str):
        """LÆ°u káº¿t quáº£ Ä‘Ã¡nh giÃ¡ vÃ o user-data.yaml"""
        # Táº¡o entry má»›i
        wrong_words_data = []
        
        for error in self.word_errors:
            if error.error_type != "missing":  # Chá»‰ lÆ°u tá»« bá»‹ phÃ¡t Ã¢m sai, khÃ´ng lÆ°u tá»« thiáº¿u
                wrong_ipa_sounds = self._extract_wrong_ipa_sounds(error)
                if wrong_ipa_sounds:  # Chá»‰ thÃªm náº¿u cÃ³ Ã¢m bá»‹ sai
                    wrong_words_data.append({
                        "word": error.word,
                        "wrong_ipa": wrong_ipa_sounds
                    })
        
        # Táº¡o node má»›i
        new_entry = {
            "sentence": original_text.strip(),
            "result": len(self.word_errors) == 0,  # True náº¿u khÃ´ng cÃ³ lá»—i
            "wrong_words": wrong_words_data
        }
        
        # Kiá»ƒm tra xem cÃ¢u nÃ y Ä‘Ã£ tá»“n táº¡i chÆ°a
        existing_index = -1
        for i, entry in enumerate(self.user_data):
            if entry.get("sentence", "").strip().lower() == original_text.strip().lower():
                existing_index = i
                break
        
        if existing_index >= 0:
            # Cáº­p nháº­t entry cÅ©
            self.user_data[existing_index] = new_entry
            print(f"Updated existing entry for: '{original_text[:50]}...'")
        else:
            # ThÃªm entry má»›i vÃ o cuá»‘i
            self.user_data.append(new_entry)
            print(f"Added new entry for: '{original_text[:50]}...'")
        
        # LÆ°u vÃ o file
        self._save_user_data()
    
    def _identify_word_errors(self, original_words: List[str], spoken_words: List[str]) -> List[WordError]:
        """XÃ¡c Ä‘á»‹nh cÃ¡c tá»« bá»‹ phÃ¡t Ã¢m sai"""
        errors = []
        matches = self._advanced_word_matching(original_words, spoken_words)
        
        matched_original_indices = {match[0] for match in matches}
        
        for i, original_word in enumerate(original_words):
            if i not in matched_original_indices:
                # Tá»« bá»‹ thiáº¿u hoÃ n toÃ n
                expected_ipa = self._get_ipa_pronunciation(original_word)
                errors.append(WordError(
                    word=original_word,
                    expected_ipa=expected_ipa,
                    actual_ipa="[missing]",
                    error_type="missing",
                    ipa_differences=[f"missing entire word '{expected_ipa}'"]
                ))
                continue
            
            # TÃ¬m match tÆ°Æ¡ng á»©ng
            match = next(match for match in matches if match[0] == i)
            _, spoken_idx, similarity = match
            
            if similarity < 0.8:  # Threshold cho tá»« sai
                spoken_word = spoken_words[spoken_idx] if spoken_idx < len(spoken_words) else "[missing]"
                expected_ipa = self._get_ipa_pronunciation(original_word)
                actual_ipa = self._get_ipa_pronunciation(spoken_word) if spoken_word != "[missing]" else "[missing]"
                
                ipa_diffs = self._find_ipa_differences(expected_ipa, actual_ipa)
                
                error_type = "mispronounced"
                if similarity < 0.4:
                    error_type = "severely_mispronounced"
                
                errors.append(WordError(
                    word=original_word,
                    expected_ipa=expected_ipa,
                    actual_ipa=actual_ipa,
                    error_type=error_type,
                    ipa_differences=ipa_diffs
                ))
        
        return errors
    
    def assess_pronunciation(self, original_text: str, spoken_text: str, save_result: bool = True) -> str:
        """
        HÃ m chÃ­nh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ phÃ¡t Ã¢m
        
        Args:
            original_text: CÃ¢u/tá»« gá»‘c
            spoken_text: Káº¿t quáº£ tá»« Speech-to-Text
            save_result: CÃ³ lÆ°u káº¿t quáº£ vÃ o user-data.yaml khÃ´ng
            
        Returns:
            str: Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ vá»›i cÃ¢u Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u vÃ  chi tiáº¿t lá»—i
        """
        # LÃ m sáº¡ch vÃ  tÃ¡ch tá»«
        original_clean = self._clean_text(original_text)
        spoken_clean = self._clean_text(spoken_text)
        
        original_words = original_clean.split()
        spoken_words = spoken_clean.split()
        
        # TÃ¬m lá»—i
        self.word_errors = self._identify_word_errors(original_words, spoken_words)
        
        # LÆ°u káº¿t quáº£ náº¿u Ä‘Æ°á»£c yÃªu cáº§u
        if save_result:
            self._save_assessment_result(original_text, spoken_text)
        
        # Táº¡o cÃ¢u Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u
        marked_sentence = self._create_marked_sentence(original_text)
        
        # Táº¡o bÃ¡o cÃ¡o chi tiáº¿t
        result = [marked_sentence]
        result.append("")  # DÃ²ng trá»‘ng
        
        if not self.word_errors:
            result.append("âœ… PhÃ¡t Ã¢m chÃ­nh xÃ¡c!")
            return "\n".join(result)
        
        result.append("âŒ CÃ¡c lá»—i phÃ¡t Ã¢m Ä‘Æ°á»£c phÃ¡t hiá»‡n:")
        result.append("")
        
        for error in self.word_errors:
            result.append(f"ðŸ”¸ Tá»« '{error.word}':")
            result.append(f"   Expected IPA: {error.expected_ipa}")
            result.append(f"   Actual IPA:   {error.actual_ipa}")
            result.append(f"   Error type:   {error.error_type}")
            if error.ipa_differences:
                result.append(f"   IPA differences: {', '.join(error.ipa_differences)}")
            result.append("")
        
        return "\n".join(result)
    
    def _create_marked_sentence(self, original_text: str) -> str:
        """Táº¡o cÃ¢u Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u vá»›i tá»« sai"""
        words = original_text.split()
        error_words = {error.word.lower() for error in self.word_errors}
        
        marked_words = []
        for word in words:
            clean_word = re.sub(r'[^\w]', '', word.lower())
            if clean_word in error_words:
                marked_words.append(f"**{word}**")
            else:
                marked_words.append(word)
        
        return " ".join(marked_words)
    
    def get_user_statistics(self) -> Dict:
        """Láº¥y thá»‘ng kÃª tá»« dá»¯ liá»‡u user"""
        if not self.user_data:
            return {
                "total_assessments": 0,
                "correct_assessments": 0,
                "accuracy_rate": 0.0,
                "most_common_wrong_words": [],
                "most_common_wrong_sounds": []
            }
        
        total = len(self.user_data)
        correct = sum(1 for entry in self.user_data if entry.get("result", False))
        accuracy_rate = (correct / total) * 100 if total > 0 else 0
        
        # Thá»‘ng kÃª tá»« sai nhiá»u nháº¥t
        wrong_words_count = {}
        wrong_sounds_count = {}
        
        for entry in self.user_data:
            for wrong_word in entry.get("wrong_words", []):
                word = wrong_word.get("word", "")
                if word:
                    wrong_words_count[word] = wrong_words_count.get(word, 0) + 1
                
                for sound in wrong_word.get("wrong_ipa", []):
                    wrong_sounds_count[sound] = wrong_sounds_count.get(sound, 0) + 1
        
        # Sáº¯p xáº¿p theo táº§n suáº¥t
        most_common_words = sorted(wrong_words_count.items(), key=lambda x: x[1], reverse=True)[:10]
        most_common_sounds = sorted(wrong_sounds_count.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            "total_assessments": total,
            "correct_assessments": correct,
            "accuracy_rate": round(accuracy_rate, 2),
            "most_common_wrong_words": most_common_words,
            "most_common_wrong_sounds": most_common_sounds
        }
    
    def print_user_statistics(self):
        """In thá»‘ng kÃª user ra console"""
        stats = self.get_user_statistics()
        
        print("\n" + "="*50)
        print("ðŸ“Š THá»NG KÃŠ PHÃT Ã‚M Cá»¦A USER")
        print("="*50)
        print(f"Tá»•ng sá»‘ láº§n kiá»ƒm tra: {stats['total_assessments']}")
        print(f"Sá»‘ láº§n Ä‘Ãºng: {stats['correct_assessments']}")
        print(f"Tá»· lá»‡ chÃ­nh xÃ¡c: {stats['accuracy_rate']}%")
        print()
        
        if stats['most_common_wrong_words']:
            print("ðŸ”´ Tá»« phÃ¡t Ã¢m sai nhiá»u nháº¥t:")
            for word, count in stats['most_common_wrong_words']:
                print(f"   â€¢ {word}: {count} láº§n")
            print()
        
        if stats['most_common_wrong_sounds']:
            print("ðŸ”´ Ã‚m IPA sai nhiá»u nháº¥t:")
            for sound, count in stats['most_common_wrong_sounds']:
                print(f"   â€¢ /{sound}/: {count} láº§n")
        
        print("="*50)


def assess_pronunciation(original_text: str, spoken_text: str, save_result: bool = True) -> str:
    """
    HÃ m wrapper Ä‘á»ƒ dá»… import vÃ  sá»­ dá»¥ng
    
    Args:
        original_text: CÃ¢u/tá»« gá»‘c
        spoken_text: Káº¿t quáº£ tá»« Speech-to-Text
        save_result: CÃ³ lÆ°u káº¿t quáº£ vÃ o user-data.yaml khÃ´ng
        
    Returns:
        str: Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ chi tiáº¿t
    """
    assessor = PronunciationAssessment()
    return assessor.assess_pronunciation(original_text, spoken_text, save_result)


def main():
    """ChÆ°Æ¡ng trÃ¬nh chÃ­nh Ä‘á»ƒ test"""
    print("=== Pronunciation Assessment Tool ===")
    print()
    
    assessor = PronunciationAssessment()
    
    # Test cases
    test_cases = [
        ("I would like a cup of coffee, please.", "I wood like a cup of coffe please"),
        ("The weather is beautiful today.", "The wether is butiful today"),
        ("She sells seashells by the seashore.", "She sells seeshells by the seeshore"),
        ("Hello world", "Hello word"),
        ("Good morning", "Good morening"),
    ]
    
    print("ðŸ§ª Running test cases...")
    for i, (original, spoken) in enumerate(test_cases, 1):
        print(f"\nTest {i}:")
        print(f"Original: {original}")
        print(f"Spoken:   {spoken}")
        print()
        
        result = assessor.assess_pronunciation(original, spoken)
        print(result)
        print("="*60)
    
    # Hiá»ƒn thá»‹ thá»‘ng kÃª
    assessor.print_user_statistics()
    
    # Interactive mode
    while True:
        print("\nðŸŽ¤ Interactive Mode")
        print("Options:")
        print("1. Assess pronunciation")
        print("2. View statistics")
        print("3. Exit")
        
        choice = input("Choose option (1-3): ").strip()
        
        if choice == '1':
            original = input("\nEnter original text: ").strip()
            if not original:
                continue
                
            spoken = input("Enter spoken text (from Speech-to-Text): ").strip()
            if not spoken:
                continue
                
            print("\n" + "="*50)
            result = assessor.assess_pronunciation(original, spoken)
            print(result)
            print("="*50)
            
        elif choice == '2':
            assessor.print_user_statistics()
            
        elif choice == '3':
            print("Goodbye!")
            break
            
        else:
            print("Invalid choice. Please choose 1-3.")


if __name__ == "__main__":
    main()